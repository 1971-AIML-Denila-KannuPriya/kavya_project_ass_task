{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ed4b35",
   "metadata": {},
   "source": [
    "1. Implement a K-Nearest Neighbors (KNN) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe2b661-7e17-4ad3-b502-eae654ac4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(point1: Tuple[float, float], point2: Tuple[float, float]) -> float:\n",
    "    # Calculate the Euclidean distance between two points\n",
    "    return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "def knn_classifier(data_points: List[Tuple[float, float, str]], new_point: Tuple[float, float], k: int = 3) -> str:\n",
    "    # Calculate the distance from new_point to all data points\n",
    "    distances = []\n",
    "    for point in data_points:\n",
    "        distance = euclidean_distance(new_point, (point[0], point[1]))\n",
    "        distances.append((distance, point[2]))  # Append (distance, label)\n",
    "    \n",
    "    # Sort the distances by ascending order\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Get the top k nearest neighbors (k=3 by default)\n",
    "    nearest_neighbors = [label for _, label in distances[:k]]\n",
    "    \n",
    "    # Determine the most common label among the nearest neighbors\n",
    "    most_common_label = Counter(nearest_neighbors).most_common(1)[0][0]\n",
    "    \n",
    "    return most_common_label\n",
    "\n",
    "# Example usage\n",
    "data_points = [(1.0, 2.0, 'A'), (2.0, 3.0, 'A'), (3.0, 4.0, 'B'), (5.0, 6.0, 'B')]\n",
    "new_point = (3.5, 4.5)\n",
    "predicted_label = knn_classifier(data_points, new_point)\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e676cd",
   "metadata": {},
   "source": [
    "2. Remove Outliers from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aec647c-62b2-4548-a586-10bbae56967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data without outliers: [10, 12, 13, 14, 100, 15, 16, 17, 120]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from typing import List\n",
    "import statistics\n",
    "\n",
    "def remove_outliers(data: List[float]) -> List[float]:\n",
    "    if len(data) < 2:\n",
    "        return data  # If there are fewer than 2 numbers, no outliers to remove\n",
    "    \n",
    "    # Calculate mean and standard deviation\n",
    "    mean = statistics.mean(data)\n",
    "    std_dev = statistics.stdev(data)\n",
    "    \n",
    "    # Define the range within which numbers are not considered outliers\n",
    "    lower_bound = mean - 2 * std_dev\n",
    "    upper_bound = mean + 2 * std_dev\n",
    "    \n",
    "    # Filter and return numbers that are within the range\n",
    "    filtered_data = [x for x in data if lower_bound <= x <= upper_bound]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Example usage\n",
    "data = [10, 12, 13, 14, 100, 15, 16, 17, 120]\n",
    "filtered_data = remove_outliers(data)\n",
    "print(f\"Data without outliers: {filtered_data}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29722582",
   "metadata": {},
   "source": [
    "3. Optimize a Matrix Multiplication for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e53b03-4909-4ac2-832d-b92bb3ecd41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 64]\n",
      "[139, 154]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List\n",
    "\n",
    "def matrix_multiply(mat1: List[List[int]], mat2: List[List[int]]) -> List[List[int]]:\n",
    "    # Check if matrix multiplication is possible (columns of mat1 == rows of mat2)\n",
    "    if len(mat1[0]) != len(mat2):\n",
    "        raise ValueError(\"Incompatible matrices: Columns of mat1 must match rows of mat2.\")\n",
    "    \n",
    "    # Dimensions of the result matrix: rows of mat1 x columns of mat2\n",
    "    result_rows = len(mat1)\n",
    "    result_cols = len(mat2[0])\n",
    "    \n",
    "    # Initialize the result matrix with zeros\n",
    "    result = [[0 for _ in range(result_cols)] for _ in range(result_rows)]\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    for i in range(result_rows):\n",
    "        for j in range(result_cols):\n",
    "            for k in range(len(mat1[0])):  # This is the shared dimension\n",
    "                result[i][j] += mat1[i][k] * mat2[k][j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "mat1 = [[1, 2, 3], [4, 5, 6]]\n",
    "mat2 = [[7, 8], [9, 10], [11, 12]]\n",
    "\n",
    "result = matrix_multiply(mat1, mat2)\n",
    "for row in result:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13037770",
   "metadata": {},
   "source": [
    "4. Word Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e26616-b646-43f7-9db0-045cc968bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9746318461970762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List\n",
    "import math\n",
    "\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    # Ensure the vectors have the same length\n",
    "    if len(vec1) != len(vec2):\n",
    "        raise ValueError(\"Vectors must be of the same length\")\n",
    "    \n",
    "    # Calculate dot product\n",
    "    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "    \n",
    "    # Calculate magnitudes of vec1 and vec2\n",
    "    magnitude_vec1 = math.sqrt(sum(a ** 2 for a in vec1))\n",
    "    magnitude_vec2 = math.sqrt(sum(b ** 2 for b in vec2))\n",
    "    \n",
    "    # Avoid division by zero by checking if any magnitude is zero\n",
    "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
    "        raise ValueError(\"One of the vectors has zero magnitude, cannot compute cosine similarity\")\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "# Example usage\n",
    "vec1 = [1.0, 2.0, 3.0]\n",
    "vec2 = [4.0, 5.0, 6.0]\n",
    "\n",
    "similarity = cosine_similarity(vec1, vec2)\n",
    "print(f\"Cosine Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0f72f",
   "metadata": {},
   "source": [
    "5. Implement a Min-Heap Using a Priority Queue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c28ca3-1b49-4d46-b3cd-b1335c50112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value: 1\n",
      "Extract minimum: 1\n",
      "Minimum value after extraction: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import heapq\n",
    "\n",
    "class MinHeap:\n",
    "    def __init__(self):\n",
    "        # Initialize an empty list to hold the heap elements\n",
    "        self.heap = []\n",
    "    \n",
    "    def insert(self, value: int) -> None:\n",
    "        \"\"\"Insert a value into the heap.\"\"\"\n",
    "        heapq.heappush(self.heap, value)\n",
    "    \n",
    "    def get_min(self) -> int:\n",
    "        \"\"\"Return the minimum value in the heap without removing it.\"\"\"\n",
    "        if not self.heap:\n",
    "            raise IndexError(\"Heap is empty\")\n",
    "        return self.heap[0]\n",
    "    \n",
    "    def extract_min(self) -> int:\n",
    "        \"\"\"Remove and return the minimum value from the heap.\"\"\"\n",
    "        if not self.heap:\n",
    "            raise IndexError(\"Heap is empty\")\n",
    "        return heapq.heappop(self.heap)\n",
    "\n",
    "# Example usage\n",
    "heap = MinHeap()\n",
    "heap.insert(5)\n",
    "heap.insert(3)\n",
    "heap.insert(8)\n",
    "heap.insert(1)\n",
    "\n",
    "print(\"Minimum value:\", heap.get_min())  # Output: 1\n",
    "print(\"Extract minimum:\", heap.extract_min())  # Output: 1\n",
    "print(\"Minimum value after extraction:\", heap.get_min())  # Output: 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b183fc8",
   "metadata": {},
   "source": [
    "6. Implement a Support Vector Machine (SVM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472e8ecd-eb29-4263-8a1e-8f74e2ec3a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for (2.5, 2.0): positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "class SVMClassifier:\n",
    "    def __init__(self, data_points: List[Tuple[float, float, str]]):\n",
    "        self.data_points = data_points\n",
    "        self.w = [0, 0]  # Weights (slope components of the line)\n",
    "        self.b = 0       # Bias term (intercept)\n",
    "    \n",
    "    def train(self, learning_rate: float = 0.01, epochs: int = 1000) -> None:\n",
    "        \"\"\"Train the SVM classifier using a simplified perceptron-based approach.\"\"\"\n",
    "        for _ in range(epochs):\n",
    "            for (x, y, label) in self.data_points:\n",
    "                # Convert labels to +1 or -1\n",
    "                label = 1 if label == 'positive' else -1\n",
    "                # Check if the point is correctly classified\n",
    "                if label * (self.w[0] * x + self.w[1] * y + self.b) <= 0:\n",
    "                    # Misclassified point, adjust weights and bias\n",
    "                    self.w[0] += learning_rate * label * x\n",
    "                    self.w[1] += learning_rate * label * y\n",
    "                    self.b += learning_rate * label\n",
    "    \n",
    "    def predict(self, new_point: Tuple[float, float]) -> str:\n",
    "        \"\"\"Predict the label of a new point based on the learned hyperplane.\"\"\"\n",
    "        x, y = new_point\n",
    "        # Calculate the decision value for the new point\n",
    "        decision_value = self.w[0] * x + self.w[1] * y + self.b\n",
    "        # Return the predicted label\n",
    "        return 'positive' if decision_value  >= 0 else 'negative'\n",
    "\n",
    "# Example usage\n",
    "data_points = [\n",
    "    (2.0, 3.0, 'positive'),\n",
    "    (1.0, 1.0, 'negative'),\n",
    "    (2.0, 1.5, 'positive'),\n",
    "    (3.0, 2.0, 'positive'),\n",
    "    (1.5, 0.5, 'negative')\n",
    "]\n",
    "\n",
    "# Create SVM classifier instance and train it\n",
    "svm = SVMClassifier(data_points)\n",
    "svm.train()\n",
    "\n",
    "# Predict label for a new point\n",
    "new_point = (2.5, 2.0)\n",
    "predicted_label = svm.predict(new_point)\n",
    "print(f\"Predicted label for {new_point}: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a25ebb",
   "metadata": {},
   "source": [
    "7  Calculate the Z-Score of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7540b5-5530-4ebc-a027-fd5820fd8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Scores: [-1.414213562373095, -0.7071067811865475, 0.0, 0.7071067811865475, 1.414213562373095]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List\n",
    "import math\n",
    "\n",
    "def calculate_z_scores(data: List[float]) -> List[float]:\n",
    "    if not data:\n",
    "        raise ValueError(\"The data list cannot be empty\")\n",
    "    \n",
    "    # Step 1: Calculate the mean\n",
    "    mean = sum(data) / len(data)\n",
    "    \n",
    "    # Step 2: Calculate the standard deviation\n",
    "    variance = sum((x - mean) ** 2 for x in data) / len(data)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    \n",
    "    # Step 3: Calculate z-scores for each data point\n",
    "    z_scores = [(x - mean) / std_dev for x in data]\n",
    "    \n",
    "    return z_scores\n",
    "\n",
    "# Example usage\n",
    "data = [10, 20, 30, 40, 50]\n",
    "z_scores = calculate_z_scores(data)\n",
    "print(f\"Z-Scores: {z_scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64cf00",
   "metadata": {},
   "source": [
    "8. K-Means Clustering Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c082ac8-1399-4496-b75b-cba4c757efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids of the clusters: [(7.333333333333333, 9.0), (1.1666666666666667, 1.4666666666666668)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "import math\n",
    "\n",
    "def calculate_distance(point1: Tuple[float, float], point2: Tuple[float, float]) -> float:\n",
    "    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n",
    "    return math.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "def k_means_clustering(data_points: List[Tuple[float, float]], k: int) -> List[Tuple[float, float]]:\n",
    "    if k <= 0 or k > len(data_points):\n",
    "        raise ValueError(\"k must be a positive integer less than or equal to the number of data points.\")\n",
    "    \n",
    "    # Step 1: Initialize centroids by randomly selecting k data points\n",
    "    centroids = random.sample(data_points, k)\n",
    "    previous_centroids = None\n",
    "    \n",
    "    while previous_centroids != centroids:\n",
    "        previous_centroids = centroids.copy()\n",
    "        \n",
    "        # Step 2: Assignment step\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        for point in data_points:\n",
    "            distances = [calculate_distance(point, centroid) for centroid in centroids]\n",
    "            nearest_centroid_index = distances.index(min(distances))\n",
    "            clusters[nearest_centroid_index].append(point)\n",
    "        \n",
    "        # Step 3: Update step\n",
    "        centroids = []\n",
    "        for cluster in clusters:\n",
    "            if cluster:  # Avoid empty clusters\n",
    "                mean_x = sum(point[0] for point in cluster) / len(cluster)\n",
    "                mean_y = sum(point[1] for point in cluster) / len(cluster)\n",
    "                centroids.append((mean_x, mean_y))\n",
    "            else:\n",
    "                # If a cluster is empty, reinitialize it with a random data point\n",
    "                centroids.append(random.choice(data_points))\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "# Example usage\n",
    "data_points = [\n",
    "    (1.0, 2.0), (1.5, 1.8), (5.0, 8.0), \n",
    "    (8.0, 8.0), (1.0, 0.6), (9.0, 11.0)\n",
    "]\n",
    "k = 2\n",
    "centroids = k_means_clustering(data_points, k)\n",
    "print(f\"Centroids of the clusters: {centroids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25bb20",
   "metadata": {},
   "source": [
    "9. Evaluate Classification Model Using F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dfc8271-f9a6-493d-bb0d-2bb0b2b746fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def f1_score(true_labels: List[int], predicted_labels: List[int]) -> float:\n",
    "    if len(true_labels) == 0:\n",
    "        raise ValueError(\"The true labels list cannot be empty.\")\n",
    "    \n",
    "    # Step 1: Calculate TP, FP, FN\n",
    "    TP = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == 1 and pred == 1)\n",
    "    FP = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == 0 and pred == 1)\n",
    "    FN = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == 1 and pred == 0)\n",
    "    \n",
    "    # Step 2: Calculate Precision and Recall\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # Step 3: Calculate F1 Score\n",
    "    if precision + recall == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Example usage\n",
    "true_labels = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
    "predicted_labels = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bdce3",
   "metadata": {},
   "source": [
    "10. Visualize Data Distribution Using a Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883d569b-b93f-499d-9137-32ef15e3dc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[1.50, 2.88)': 2, '[2.88, 4.25)': 3, '[4.25, 5.62)': 2, '[5.62, 7.00)': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def create_histogram(data: List[float], bins: int) -> Dict[str, int]:\n",
    "    if bins <= 0:\n",
    "        raise ValueError(\"The number of bins must be a positive integer.\")\n",
    "    \n",
    "    if not data:\n",
    "        return {}\n",
    "    \n",
    "    # Step 1: Calculate the range of the data\n",
    "    min_value = min(data)\n",
    "    max_value = max(data)\n",
    "    \n",
    "    # Step 2: Calculate the width of each bin\n",
    "    bin_width = (max_value - min_value) / bins\n",
    "    \n",
    "    # Step 3: Create the histogram dictionary\n",
    "    histogram = {}\n",
    "    \n",
    "    # Step 4: Count data points in each bin\n",
    "    for i in range(bins):\n",
    "        lower_bound = min_value + i * bin_width\n",
    "        upper_bound = min_value + (i + 1) * bin_width\n",
    "        bin_range = f\"[{lower_bound:.2f}, {upper_bound:.2f})\"  # Format for bin range\n",
    "        count = sum(1 for value in data if lower_bound <= value < upper_bound)\n",
    "        \n",
    "        # Add to the histogram dictionary\n",
    "        histogram[bin_range] = count\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# Example usage\n",
    "data = [1.5, 2.3, 2.9, 3.7, 4.1, 4.8, 5.5, 5.8, 6.3, 7.0]\n",
    "bins = 4\n",
    "histogram = create_histogram(data, bins)\n",
    "print(histogram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ee9cb",
   "metadata": {},
   "source": [
    "11. Implement a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fe66a4-79e1-4158-b1c4-4019777a2e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for [5.0, 7.0]: B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Index of the feature to split\n",
    "        self.threshold = threshold            # Threshold value for the split\n",
    "        self.left = left                      # Left subtree\n",
    "        self.right = right                    # Right subtree\n",
    "        self.value = value                    # Class label if leaf node\n",
    "\n",
    "def gini_impurity(labels: List[str]) -> float:\n",
    "    \"\"\"Calculate the Gini impurity for a list of labels.\"\"\"\n",
    "    if not labels:\n",
    "        return 0\n",
    "    total = len(labels)\n",
    "    label_counts = {}\n",
    "    for label in labels:\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    impurity = 1.0\n",
    "    for count in label_counts.values():\n",
    "        prob = count / total\n",
    "        impurity -= prob ** 2\n",
    "    return impurity\n",
    "\n",
    "def best_split(data_points: List[Tuple[List[float], str]]) -> Tuple[int, float]:\n",
    "    \"\"\"Find the best feature and threshold to split the dataset.\"\"\"\n",
    "    best_impurity = float('inf')\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "\n",
    "    features = list(zip(*[x for x, _ in data_points]))  # Transpose to get features\n",
    "\n",
    "    for feature_index in range(len(features)):\n",
    "        thresholds = sorted(set(features[feature_index]))\n",
    "        for threshold in thresholds:\n",
    "            left_labels = [label for (features, label) in data_points if features[feature_index] <= threshold]\n",
    "            right_labels = [label for (features, label) in data_points if features[feature_index] > threshold]\n",
    "            \n",
    "            impurity = (len(left_labels) / len(data_points)) * gini_impurity(left_labels) + \\\n",
    "                       (len(right_labels) / len(data_points)) * gini_impurity(right_labels)\n",
    "\n",
    "            if impurity < best_impurity:\n",
    "                best_impurity = impurity\n",
    "                best_feature = feature_index\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "def build_tree(data_points: List[Tuple[List[float], str]], depth: int = 0, max_depth: int = 5) -> TreeNode:\n",
    "    \"\"\"Recursively build the decision tree.\"\"\"\n",
    "    labels = [label for (_, label) in data_points]\n",
    "\n",
    "    # If all labels are the same or max depth is reached, create a leaf node\n",
    "    if len(set(labels)) == 1 or depth >= max_depth:\n",
    "        return TreeNode(value=labels[0])\n",
    "\n",
    "    # Find the best feature to split\n",
    "    feature_index, threshold = best_split(data_points)\n",
    "\n",
    "    if feature_index is None:\n",
    "        return TreeNode(value=max(labels, key=labels.count))  # Return the majority label if no split found\n",
    "\n",
    "    left_data = [(features, label) for (features, label) in data_points if features[feature_index] <= threshold]\n",
    "    right_data = [(features, label) for (features, label) in data_points if features[feature_index] > threshold]\n",
    "\n",
    "    # Create subtrees\n",
    "    left_subtree = build_tree(left_data, depth + 1, max_depth)\n",
    "    right_subtree = build_tree(right_data, depth + 1, max_depth)\n",
    "\n",
    "    return TreeNode(feature_index=feature_index, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "\n",
    "def predict(tree: TreeNode, instance: List[float]) -> str:\n",
    "    \"\"\"Make a prediction for a new instance.\"\"\"\n",
    "    if tree.value is not None:  # Leaf node\n",
    "        return tree.value\n",
    "    if instance[tree.feature_index] <= tree.threshold:\n",
    "        return predict(tree.left, instance)\n",
    "    else:\n",
    "        return predict(tree.right, instance)\n",
    "\n",
    "def decision_tree_classifier(data_points: List[Tuple[List[float], str]], new_point: List[float]) -> str:\n",
    "    \"\"\"Predict the label of a new instance using a decision tree.\"\"\"\n",
    "    tree = build_tree(data_points)\n",
    "    return predict(tree, new_point)\n",
    "\n",
    "# Example usage\n",
    "data_points = [\n",
    "    ([1.0, 2.0], 'A'),\n",
    "    ([1.5, 1.8], 'A'),\n",
    "    ([5.0, 8.0], 'B'),\n",
    "    ([6.0, 9.0], 'B'),\n",
    "    ([1.0, 0.6], 'A'),\n",
    "    ([5.5, 6.0], 'B')\n",
    "]\n",
    "\n",
    "new_point = [5.0, 7.0]\n",
    "predicted_label = decision_tree_classifier(data_points, new_point)\n",
    "print(f\"Predicted label for {new_point}: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270ec4e",
   "metadata": {},
   "source": [
    "12. Normalize Data Using Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4c7fc6-319b-4027-8d2d-291a4b164ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.25, 0.5, 0.75, 1.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def min_max_normalization(data: List[float]) -> List[float]:\n",
    "    if not data:\n",
    "        return []\n",
    "    \n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    \n",
    "    # Handle case when all data points are the same (to avoid division by zero)\n",
    "    if min_val == max_val:\n",
    "        return [0.0 for _ in data]\n",
    "    \n",
    "    normalized_data = [(x - min_val) / (max_val - min_val) for x in data]\n",
    "    \n",
    "    return normalized_data\n",
    "data = [10, 20, 30, 40, 50]\n",
    "normalized_data = min_max_normalization(data)\n",
    "print(normalized_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f236ab58",
   "metadata": {},
   "source": [
    "13. Calculate distance between two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f823dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0710678118654755\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "def euclidean_distance(point1: List[float], point2: List[float]) -> float:\n",
    "    # Ensure both points have the same dimensionality\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Points must have the same number of dimensions.\")\n",
    "    \n",
    "    # Calculate the Euclidean distance\n",
    "    distance = math.sqrt(sum((x - y) ** 2 for x, y in zip(point1, point2)))\n",
    "    \n",
    "    return distance\n",
    "point1 = [1.0, 2.0, 3.0]\n",
    "point2 = [4.0, 6.0, 8.0]\n",
    "\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b4f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
